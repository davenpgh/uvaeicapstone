{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9d4ee7-38e7-47c8-be4d-b7e8fd1570f2",
   "metadata": {},
   "source": [
    "### Simple MLP Regression\n",
    "\n",
    "The y variable is a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286b5b56-cc2c-4781-ad39-45a7818889ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6bbe68-4017-449a-8a11-235abfea3ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc2e5c-0b13-44b7-bf03-debb62b6f12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e08219-6889-41a9-9c7c-4b220fbcaf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "      <th>1422</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>0.090254</td>\n",
       "      <td>0.084485</td>\n",
       "      <td>0.088903</td>\n",
       "      <td>0.108869</td>\n",
       "      <td>0.122916</td>\n",
       "      <td>0.122004</td>\n",
       "      <td>0.137874</td>\n",
       "      <td>0.156553</td>\n",
       "      <td>0.166525</td>\n",
       "      <td>0.177956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269014</td>\n",
       "      <td>0.268746</td>\n",
       "      <td>0.285345</td>\n",
       "      <td>0.301515</td>\n",
       "      <td>0.310147</td>\n",
       "      <td>0.317664</td>\n",
       "      <td>0.346122</td>\n",
       "      <td>0.374291</td>\n",
       "      <td>0.419284</td>\n",
       "      <td>0.437599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSCI</th>\n",
       "      <td>0.595959</td>\n",
       "      <td>0.091255</td>\n",
       "      <td>0.090562</td>\n",
       "      <td>0.164876</td>\n",
       "      <td>0.203418</td>\n",
       "      <td>0.052459</td>\n",
       "      <td>0.073621</td>\n",
       "      <td>0.143967</td>\n",
       "      <td>0.083131</td>\n",
       "      <td>0.194034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.034764</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.090814</td>\n",
       "      <td>0.055294</td>\n",
       "      <td>0.036332</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.144786</td>\n",
       "      <td>0.078785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VACO2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422880</td>\n",
       "      <td>0.740739</td>\n",
       "      <td>0.242746</td>\n",
       "      <td>0.032386</td>\n",
       "      <td>0.415422</td>\n",
       "      <td>0.504482</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>0.643925</td>\n",
       "      <td>0.405723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415422</td>\n",
       "      <td>0.504482</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>0.643925</td>\n",
       "      <td>0.405723</td>\n",
       "      <td>0.643461</td>\n",
       "      <td>0.470033</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>51067.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "      <td>51093.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture</th>\n",
       "      <td>0.120512</td>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.087572</td>\n",
       "      <td>0.088977</td>\n",
       "      <td>0.086611</td>\n",
       "      <td>0.082118</td>\n",
       "      <td>0.083991</td>\n",
       "      <td>0.137212</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.126597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.275985</td>\n",
       "      <td>0.282213</td>\n",
       "      <td>0.269258</td>\n",
       "      <td>0.284880</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>0.288809</td>\n",
       "      <td>0.284157</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aquaculture</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barren</th>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developed</th>\n",
       "      <td>0.042941</td>\n",
       "      <td>0.042546</td>\n",
       "      <td>0.040608</td>\n",
       "      <td>0.042279</td>\n",
       "      <td>0.042493</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.046297</td>\n",
       "      <td>0.045958</td>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.046270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078862</td>\n",
       "      <td>0.079153</td>\n",
       "      <td>0.076714</td>\n",
       "      <td>0.076204</td>\n",
       "      <td>0.076148</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>0.070008</td>\n",
       "      <td>0.070222</td>\n",
       "      <td>0.081463</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forest</th>\n",
       "      <td>0.663460</td>\n",
       "      <td>0.662633</td>\n",
       "      <td>0.660032</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.673071</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.653685</td>\n",
       "      <td>0.679065</td>\n",
       "      <td>0.682611</td>\n",
       "      <td>0.688918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380312</td>\n",
       "      <td>0.286815</td>\n",
       "      <td>0.307997</td>\n",
       "      <td>0.304446</td>\n",
       "      <td>0.295225</td>\n",
       "      <td>0.294034</td>\n",
       "      <td>0.373395</td>\n",
       "      <td>0.370450</td>\n",
       "      <td>0.354811</td>\n",
       "      <td>0.366529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grassland</th>\n",
       "      <td>0.145732</td>\n",
       "      <td>0.161879</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.166330</td>\n",
       "      <td>0.166485</td>\n",
       "      <td>0.180652</td>\n",
       "      <td>0.184273</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>0.108259</td>\n",
       "      <td>0.105471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.036858</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.016196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open_Water</th>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.027313</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.027358</td>\n",
       "      <td>0.027184</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.027263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.013525</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.014753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shrubland</th>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048493</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>0.101836</td>\n",
       "      <td>0.108072</td>\n",
       "      <td>0.100246</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.019972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wetlands</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181455</td>\n",
       "      <td>0.216304</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0.215325</td>\n",
       "      <td>0.219187</td>\n",
       "      <td>0.206370</td>\n",
       "      <td>0.220201</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>0.218629</td>\n",
       "      <td>0.208846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 1425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0             1             2             3     \\\n",
       "Income           0.090254      0.084485      0.088903      0.108869   \n",
       "DSCI             0.595959      0.091255      0.090562      0.164876   \n",
       "VACO2            1.000000      0.422880      0.740739      0.242746   \n",
       "County       51067.000000  51067.000000  51067.000000  51067.000000   \n",
       "Agriculture      0.120512      0.103555      0.087572      0.088977   \n",
       "Aquaculture      0.000000      0.000000      0.000000      0.000000   \n",
       "Barren           0.000806      0.001854      0.001828      0.002897   \n",
       "Developed        0.042941      0.042546      0.040608      0.042279   \n",
       "Forest           0.663460      0.662633      0.660032      0.672473   \n",
       "Grassland        0.145732      0.161879      0.181759      0.166330   \n",
       "Open_Water       0.026327      0.027040      0.027313      0.026095   \n",
       "Shrubland        0.000216      0.000486      0.000887      0.000917   \n",
       "Wetlands         0.000005      0.000007      0.000000      0.000031   \n",
       "2008             1.000000      0.000000      0.000000      0.000000   \n",
       "2009             0.000000      1.000000      0.000000      0.000000   \n",
       "2010             0.000000      0.000000      1.000000      0.000000   \n",
       "2011             0.000000      0.000000      0.000000      1.000000   \n",
       "2012             0.000000      0.000000      0.000000      0.000000   \n",
       "2013             0.000000      0.000000      0.000000      0.000000   \n",
       "2014             0.000000      0.000000      0.000000      0.000000   \n",
       "2015             0.000000      0.000000      0.000000      0.000000   \n",
       "2016             0.000000      0.000000      0.000000      0.000000   \n",
       "2017             0.000000      0.000000      0.000000      0.000000   \n",
       "2018             0.000000      0.000000      0.000000      0.000000   \n",
       "2019             0.000000      0.000000      0.000000      0.000000   \n",
       "2020             0.000000      0.000000      0.000000      0.000000   \n",
       "2021             0.000000      0.000000      0.000000      0.000000   \n",
       "2022             0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "                     4             5             6             7     \\\n",
       "Income           0.122916      0.122004      0.137874      0.156553   \n",
       "DSCI             0.203418      0.052459      0.073621      0.143967   \n",
       "VACO2            0.032386      0.415422      0.504482      0.513963   \n",
       "County       51067.000000  51067.000000  51067.000000  51067.000000   \n",
       "Agriculture      0.086611      0.082118      0.083991      0.137212   \n",
       "Aquaculture      0.000000      0.000000      0.000000      0.000000   \n",
       "Barren           0.003506      0.001318      0.001346      0.005751   \n",
       "Developed        0.042493      0.042105      0.046297      0.045958   \n",
       "Forest           0.673071      0.667200      0.653685      0.679065   \n",
       "Grassland        0.166485      0.180652      0.184273      0.099269   \n",
       "Open_Water       0.026633      0.026327      0.027358      0.027184   \n",
       "Shrubland        0.001170      0.000279      0.002978      0.005530   \n",
       "Wetlands         0.000031      0.000002      0.000073      0.000031   \n",
       "2008             0.000000      0.000000      0.000000      0.000000   \n",
       "2009             0.000000      0.000000      0.000000      0.000000   \n",
       "2010             0.000000      0.000000      0.000000      0.000000   \n",
       "2011             0.000000      0.000000      0.000000      0.000000   \n",
       "2012             1.000000      0.000000      0.000000      0.000000   \n",
       "2013             0.000000      1.000000      0.000000      0.000000   \n",
       "2014             0.000000      0.000000      1.000000      0.000000   \n",
       "2015             0.000000      0.000000      0.000000      1.000000   \n",
       "2016             0.000000      0.000000      0.000000      0.000000   \n",
       "2017             0.000000      0.000000      0.000000      0.000000   \n",
       "2018             0.000000      0.000000      0.000000      0.000000   \n",
       "2019             0.000000      0.000000      0.000000      0.000000   \n",
       "2020             0.000000      0.000000      0.000000      0.000000   \n",
       "2021             0.000000      0.000000      0.000000      0.000000   \n",
       "2022             0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "                     8             9     ...          1415          1416  \\\n",
       "Income           0.166525      0.177956  ...      0.269014      0.268746   \n",
       "DSCI             0.083131      0.194034  ...      0.012481      0.015996   \n",
       "VACO2            0.643925      0.405723  ...      0.415422      0.504482   \n",
       "County       51067.000000  51067.000000  ...  51093.000000  51093.000000   \n",
       "Agriculture      0.120223      0.126597  ...      0.272829      0.275985   \n",
       "Aquaculture      0.000000      0.000000  ...      0.000000      0.000000   \n",
       "Barren           0.006955      0.001059  ...      0.001142      0.001825   \n",
       "Developed        0.046477      0.046270  ...      0.078862      0.079153   \n",
       "Forest           0.682611      0.688918  ...      0.380312      0.286815   \n",
       "Grassland        0.108259      0.105471  ...      0.026616      0.036858   \n",
       "Open_Water       0.027673      0.027263  ...      0.010291      0.012502   \n",
       "Shrubland        0.007744      0.004413  ...      0.048493      0.090560   \n",
       "Wetlands         0.000058      0.000008  ...      0.181455      0.216304   \n",
       "2008             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2009             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2010             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2011             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2012             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2013             0.000000      0.000000  ...      1.000000      0.000000   \n",
       "2014             0.000000      0.000000  ...      0.000000      1.000000   \n",
       "2015             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2016             1.000000      0.000000  ...      0.000000      0.000000   \n",
       "2017             0.000000      1.000000  ...      0.000000      0.000000   \n",
       "2018             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2019             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2020             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2021             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "2022             0.000000      0.000000  ...      0.000000      0.000000   \n",
       "\n",
       "                     1417          1418          1419          1420  \\\n",
       "Income           0.285345      0.301515      0.310147      0.317664   \n",
       "DSCI             0.034764      0.017193      0.090814      0.055294   \n",
       "VACO2            0.513963      0.643925      0.405723      0.643461   \n",
       "County       51093.000000  51093.000000  51093.000000  51093.000000   \n",
       "Agriculture      0.282213      0.269258      0.284880      0.286654   \n",
       "Aquaculture      0.000000      0.000000      0.000000      0.000000   \n",
       "Barren           0.001304      0.007768      0.001515      0.004196   \n",
       "Developed        0.076714      0.076204      0.076148      0.075865   \n",
       "Forest           0.307997      0.304446      0.295225      0.294034   \n",
       "Grassland        0.010673      0.006200      0.009872      0.008047   \n",
       "Open_Water       0.013525      0.012726      0.012927      0.012790   \n",
       "Shrubland        0.101836      0.108072      0.100246      0.112044   \n",
       "Wetlands         0.205738      0.215325      0.219187      0.206370   \n",
       "2008             0.000000      0.000000      0.000000      0.000000   \n",
       "2009             0.000000      0.000000      0.000000      0.000000   \n",
       "2010             0.000000      0.000000      0.000000      0.000000   \n",
       "2011             0.000000      0.000000      0.000000      0.000000   \n",
       "2012             0.000000      0.000000      0.000000      0.000000   \n",
       "2013             0.000000      0.000000      0.000000      0.000000   \n",
       "2014             0.000000      0.000000      0.000000      0.000000   \n",
       "2015             1.000000      0.000000      0.000000      0.000000   \n",
       "2016             0.000000      1.000000      0.000000      0.000000   \n",
       "2017             0.000000      0.000000      1.000000      0.000000   \n",
       "2018             0.000000      0.000000      0.000000      1.000000   \n",
       "2019             0.000000      0.000000      0.000000      0.000000   \n",
       "2020             0.000000      0.000000      0.000000      0.000000   \n",
       "2021             0.000000      0.000000      0.000000      0.000000   \n",
       "2022             0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "                     1421          1422          1423          1424  \n",
       "Income           0.346122      0.374291      0.419284      0.437599  \n",
       "DSCI             0.036332      0.002708      0.144786      0.078785  \n",
       "VACO2            0.470033      0.011826      0.000000      0.446456  \n",
       "County       51093.000000  51093.000000  51093.000000  51093.000000  \n",
       "Agriculture      0.288809      0.284157      0.292600      0.290300  \n",
       "Aquaculture      0.000000      0.000000      0.000000      0.000000  \n",
       "Barren           0.000659      0.006378      0.000701      0.000796  \n",
       "Developed        0.070008      0.070222      0.081463      0.082609  \n",
       "Forest           0.373395      0.370450      0.354811      0.366529  \n",
       "Grassland        0.004695      0.003538      0.015733      0.016196  \n",
       "Open_Water       0.014299      0.014950      0.014813      0.014753  \n",
       "Shrubland        0.027932      0.025637      0.021250      0.019972  \n",
       "Wetlands         0.220201      0.224667      0.218629      0.208846  \n",
       "2008             0.000000      0.000000      0.000000      0.000000  \n",
       "2009             0.000000      0.000000      0.000000      0.000000  \n",
       "2010             0.000000      0.000000      0.000000      0.000000  \n",
       "2011             0.000000      0.000000      0.000000      0.000000  \n",
       "2012             0.000000      0.000000      0.000000      0.000000  \n",
       "2013             0.000000      0.000000      0.000000      0.000000  \n",
       "2014             0.000000      0.000000      0.000000      0.000000  \n",
       "2015             0.000000      0.000000      0.000000      0.000000  \n",
       "2016             0.000000      0.000000      0.000000      0.000000  \n",
       "2017             0.000000      0.000000      0.000000      0.000000  \n",
       "2018             0.000000      0.000000      0.000000      0.000000  \n",
       "2019             1.000000      0.000000      0.000000      0.000000  \n",
       "2020             0.000000      1.000000      0.000000      0.000000  \n",
       "2021             0.000000      0.000000      1.000000      0.000000  \n",
       "2022             0.000000      0.000000      0.000000      1.000000  \n",
       "\n",
       "[28 rows x 1425 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"all-county-data-no-tmpprecip.csv\")\n",
    "\n",
    "# dealing with nas\n",
    "df['VACO2'].isna().sum()\n",
    "\n",
    "# replace with median (not sure which method to choose)\n",
    "VACO2_median = df['VACO2'].median()\n",
    "df['VACO2'].fillna(VACO2_median, inplace=True)\n",
    "\n",
    "# min-max predictors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_select = ['Income', 'DSCI', 'VACO2'] \n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "scaled_cols = scaler.fit_transform(df[cols_select])\n",
    "scaled_df = pd.DataFrame(scaled_cols, columns=cols_select)\n",
    "\n",
    "cols_add = ['County','Year','Agriculture', 'Aquaculture','Barren','Developed', 'Forest','Grassland','Open_Water','Shrubland','Wetlands']\n",
    "scaled_df[cols_add] = df[cols_add]\n",
    "\n",
    "# replacing County with numeric value\n",
    "scaled_df['County'].replace(['Accomack', 'Fauquier', 'Greensville', 'Hanover', 'Rockingham', 'Wise'],\n",
    "                        [1,2,3,4,5,6], inplace=True)\n",
    "\n",
    "# one-hot code year\n",
    "onehot = pd.get_dummies(scaled_df['Year'])\n",
    "df_scaled = pd.concat([scaled_df, onehot], axis=1)\n",
    "\n",
    "# drop the original year column\n",
    "df_scaled.drop('Year', axis=1, inplace=True)\n",
    "\n",
    "# scaled data\n",
    "df_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b39217e7-6b29-426c-bbd9-cb63454171f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income         450\n",
       "DSCI             0\n",
       "VACO2            0\n",
       "County           0\n",
       "Agriculture     45\n",
       "Aquaculture     45\n",
       "Barren          45\n",
       "Developed       45\n",
       "Forest          45\n",
       "Grassland       45\n",
       "Open_Water      45\n",
       "Shrubland       45\n",
       "Wetlands        45\n",
       "2008             0\n",
       "2009             0\n",
       "2010             0\n",
       "2011             0\n",
       "2012             0\n",
       "2013             0\n",
       "2014             0\n",
       "2015             0\n",
       "2016             0\n",
       "2017             0\n",
       "2018             0\n",
       "2019             0\n",
       "2020             0\n",
       "2021             0\n",
       "2022             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c913d4-2a47-4fdc-bf29-95e03139f1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e832679d-263c-40e7-945e-2ab9460a9597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agriculture    45\n",
       "Aquaculture    45\n",
       "Barren         45\n",
       "Developed      45\n",
       "Forest         45\n",
       "Grassland      45\n",
       "Open_Water     45\n",
       "Shrubland      45\n",
       "Wetlands       45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into X and y dataframes\n",
    "\n",
    "y_vars = ['Agriculture', 'Aquaculture','Barren','Developed', 'Forest','Grassland','Open_Water','Shrubland','Wetlands']\n",
    "x_vars = df_scaled.columns[~df_scaled.columns.isin(y_vars)]\n",
    "\n",
    "y = df_scaled[y_vars]\n",
    "X = df_scaled[x_vars]\n",
    "\n",
    "X[\"Income\"].isna().sum() # 450\n",
    "# X[\"VACO2\"].isna().sum() # 0\n",
    "# X[\"DSCI\"].isna().sum() # 0\n",
    "\n",
    "#temp = X[X[\"Income\"].isna()]# 450\n",
    "#temp\n",
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87595b54-0f8c-42cd-9c2e-f45409e9dea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09025402 0.59595897 1.         ... 0.         0.         0.        ]\n",
      " [0.08448514 0.09125466 0.42288031 ... 0.         0.         0.        ]\n",
      " [0.08890295 0.0905619  0.74073902 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [       nan 0.01221767 0.01182606 ... 1.         0.         0.        ]\n",
      " [       nan 0.15775909 0.         ... 0.         1.         0.        ]\n",
      " [       nan 0.06864567 0.44645648 ... 0.         0.         1.        ]]\n",
      "----\n",
      "[[1.20511508e-01 0.00000000e+00 8.06190134e-04 ... 2.63274060e-02\n",
      "  2.15830430e-04 5.37134553e-06]\n",
      " [1.03555147e-01 0.00000000e+00 1.85409082e-03 ... 2.70403300e-02\n",
      "  4.85862619e-04 7.32456209e-06]\n",
      " [8.75724643e-02 0.00000000e+00 1.82772239e-03 ... 2.73132920e-02\n",
      "  8.87248621e-04 0.00000000e+00]\n",
      " ...\n",
      " [1.87277541e-01 0.00000000e+00 6.59639548e-04 ... 2.07958145e-02\n",
      "  1.14095051e-02 2.39910000e-04]\n",
      " [1.58816936e-01 0.00000000e+00 3.67296100e-04 ... 2.09132888e-02\n",
      "  1.02856461e-02 1.67609905e-04]\n",
      " [1.54770472e-01 0.00000000e+00 4.77067552e-04 ... 2.09873582e-02\n",
      "  9.94613564e-03 2.24528952e-04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# leave out some counties- take 80pct of counties for train and rest for test?\n",
    "\n",
    "# Try again without hard coding the numbers - take an 80% fraction or so\n",
    "# did not shuffle so that the years would stay in order... but not sure that worked...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=False, random_state=42)\n",
    "\n",
    "# NEXT TIME SPLIT BY COUNTIES/FIPS CODES\n",
    "# make list of training and eval fips code\n",
    "\n",
    "\n",
    "# save input parameters to np.array\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# (interpolation function (BEFORE SCALING)) ?? Not sure anymore what inperpolating meanss\n",
    "# imputing - handling missing data \n",
    "\n",
    "## How to deal with the years when one hot encoded like this?\n",
    "\n",
    "print(X_train)\n",
    "print('----')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364152ed-ff22-47f5-9951-6abbf4238f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa069a88-444b-4586-af35-e410e42127a2",
   "metadata": {},
   "source": [
    "#### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d82b6-8bc5-4116-9de5-830b64cfba9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd564274-7a77-4036-ba3b-3c23cf147b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nMLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the simple model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# HAVE CELL TO DEFINE HYPERPARAMETERS\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# try setting and adding activation function (logistic / softmax / tanh)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# try to make it sum to number\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# floor values (np.clip())\u001b[39;00m\n\u001b[1;32m      7\u001b[0m regr \u001b[38;5;241m=\u001b[39m \u001b[43mMLPRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_layer_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogistic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlearning_rate_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madaptive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:753\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    737\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:442\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m hidden_layer_sizes\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    438\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m incremental\n\u001b[1;32m    440\u001b[0m )\n\u001b[0;32m--> 442\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Ensure y is 2D\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1615\u001b[0m, in \u001b[0;36mMLPRegressor._validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, incremental, reset):\n\u001b[0;32m-> 1615\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1625\u001b[0m         y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nMLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Fit the simple model\n",
    "# HAVE CELL TO DEFINE HYPERPARAMETERS\n",
    "# try setting and adding activation function (logistic / softmax / tanh)\n",
    "# try to make it sum to number\n",
    "# floor values (np.clip())\n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                    random_state=1, \n",
    "                    activation='logistic',\n",
    "                    learning_rate_init=0.01, \n",
    "                    learning_rate='adaptive',\n",
    "                    max_iter=500000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f181bb-38f7-4104-8204-6f16324da93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b69d930-eec8-4625-9069-b3e179f5d154",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d00e6f9-b10b-4c42-9e28-eb8273138d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16352232,  0.01110836, -0.00264411,  0.07434502,  0.65651641,\n",
       "         0.16768583, -0.00207587,  0.01401712, -0.05169422]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for test data\n",
    "\n",
    "regr.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc961092-3440-415e-97a2-8ff459f59c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.42847564e-01, 0.00000000e+00, 8.81364203e-04, 7.14916137e-02,\n",
       "        5.92571897e-01, 8.84974808e-02, 2.88111531e-03, 6.65219150e-04,\n",
       "        1.63746252e-04]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f0b10-2584-4fad-a95c-f4cd3db0ff49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "123a1391-bc7a-4eb9-ae12-bc45f8ced0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15040753, 0.01021745, 0.        , 0.06838241, 0.60386258,\n",
       "        0.15423711, 0.        , 0.01289292, 0.        ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make this all a function for each row!! This makes is like softmax\n",
    "floored = np.clip(regr.predict(X_test[:1]), 0,1)\n",
    "sums = np.sum(floored)\n",
    "floored/sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8f6c9-7184-4af9-b56a-75e5926c7f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71e56210-c104-49ca-9e3e-edcd3f15f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mse instead of r^2 (Actual-predicted etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c62cbd2-3dfb-4992-8ac9-9ab38df08fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could compare mse and r^2 for each column to see what land use it's best at predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe2367-3029-4d70-80cb-f92b546e15f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ee2a7-dab1-4730-a1a6-cbdff337e388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93cf4423-585e-4d14-8d02-d214638ae575",
   "metadata": {},
   "source": [
    "#### Calc R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99d86df3-a36c-424e-a28a-5e2d92aadac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-386687.77663841913"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate R-squared\n",
    "\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c45fcfa7-616c-4eb8-a64c-40610e350193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26599741,  0.02257287, -0.00319977,  0.08792585,  0.30953277,\n",
       "         0.06292007,  0.01499567,  0.02365697,  0.34047509]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd2b6bf3-5b59-4865-ad0b-b6f375957e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4906.541127867366"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947e7d2c-605f-489e-b507-859e6465c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a315ca3-69db-4587-95f3-5cf2303db34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a05cd-b9e0-4f9c-bf10-3d3ac78c1c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48bcf0-cc2d-42e4-80a4-2d6938b00e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
